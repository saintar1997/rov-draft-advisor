import requests
from bs4 import BeautifulSoup
import pandas as pd

# URL ที่ต้องการดึงข้อมูล
url = "https://liquipedia.net/honorofkings/Special:RunQuery/Game_history?title=Special%3ARunQuery%2FGame_history&pfRunQueryFormName=Game+history&Gh=teams%255Bis_list%255D%3D1%26picks%255Bis_list%255D%3D1%26picksteam%3D%26picks2%255Bis_list%255D%3D1%26picks2team%3D%26bans%255Bis_list%255D%3D1%26tournaments%255B0%255D%3DRoV_Pro_League%252F2025%252FSummer%252FGroup_Stage%26tournaments%255B1%255D%3DRoV_Pro_League%252F2025%252FSummer%252FPlayoffs%26tournaments%255Bis_list%255D%3D1%26type%3D%26sdate%255Bday%255D%3D%26sdate%255Bmonth%255D%3D%26sdate%255Byear%255D%3D%26edate%255Bday%255D%3D%26edate%255Bmonth%255D%3D%26edate%255Byear%255D%3D%26limit%3D%26offset%3D%26sort%255Bis_checkbox%255D%3Dtrue&wpRunQuery=&pf_free_text=&Gh%5Bteams%5D%5Bis_list%5D=1&Gh%5Bpicks%5D%5Bis_list%5D=1&Gh%5Bpicksteam%5D=&Gh%5Bpicks2%5D%5Bis_list%5D=1&Gh%5Bpicks2team%5D=&Gh%5Bbans%5D%5Bis_list%5D=1&Gh%5Btournaments%5D%5B%5D=RoV_Pro_League%2F2025%2FSummer%2FGroup_Stage&Gh%5Btournaments%5D%5B%5D=RoV_Pro_League%2F2025%2FSummer%2FPlayoffs&Gh%5Btournaments%5D%5Bis_list%5D=1&Gh%5Btype%5D=&Gh%5Bsdate%5D%5Bday%5D=&Gh%5Bsdate%5D%5Bmonth%5D=&Gh%5Bsdate%5D%5Byear%5D=&Gh%5Bedate%5D%5Bday%5D=&Gh%5Bedate%5D%5Bmonth%5D=&Gh%5Bedate%5D%5Byear%5D=&Gh%5Blimit%5D=&Gh%5Boffset%5D=&Gh%5Bsort%5D%5Bis_checkbox%5D=true&wpRunQuery=&pf_free_text="

# ดึงข้อมูลจาก URL
response = requests.get(url)
soup = BeautifulSoup(response.content, 'html.parser')

# ค้นหาตารางข้อมูล
table = soup.find("table", class_="wikitable table-striped sortable")

# ชื่อคอลัมน์ในตาราง
columns = [
    "Date", "Tournament", "Game", "Team 1", 
    "Slayer (T1)", "Farm (T1)", "Mid (T1)", "Abyssal (T1)", "Support (T1)",
    "Ban 1 (T1)", "Ban 2 (T1)",
    "Team 2", 
    "Slayer (T2)", "Farm (T2)", "Mid (T2)", "Abyssal (T2)", "Support (T2)",
    "Ban 1 (T2)", "Ban 2 (T2)", 
    "Winner", "Length", "VOD"
]

# เตรียมข้อมูลสำหรับ DataFrame
data = []

# ฟังก์ชันช่วยในการแยก Draft และ Ban
def parse_draft(cell):
    # ดึง Hero ทั้งหมดใน Draft
    all_heroes = [a['title'] for a in cell.find_all("a") if "title" in a.attrs]
    
    # ดึง Hero ใน Ban โดยค้นหาภายใน <span class="bans-filter ml-2">
    bans_span = cell.find("span", class_="bans-filter ml-2")
    if bans_span:
        bans = [a['title'] for a in bans_span.find_all("a")]
    else:
        bans = []

    # เอา Ban ออกจาก Draft
    picks = [hero for hero in all_heroes if hero not in bans]

    # จัดตำแหน่งใน Draft ตามลำดับ
    draft = picks[:5] + [""] * (5 - len(picks))
    ban = bans[:2] + [""] * (2 - len(bans))
    return draft, ban

# อ่านข้อมูลในแต่ละแถวของตาราง
for row in table.find_all("tr")[1:]:
    cells = row.find_all("td")
    if len(cells) < 10:
        continue

    # ข้อมูลพื้นฐาน
    date = cells[0].text.strip()
    tournament = cells[1].text.strip()
    game = cells[2].text.strip()
    team1 = cells[3].text.strip()
    team2 = cells[5].text.strip()
    winner = cells[7].text.strip()
    length = cells[8].text.strip()
    vod = cells[9].text.strip()

    # ดึงข้อมูลการ Draft และ Ban
    draft1, ban1 = parse_draft(cells[4])
    draft2, ban2 = parse_draft(cells[6])

    # แยก Draft เป็นช่องสำหรับแต่ละตำแหน่ง
    draft1_positions = draft1[:5]
    draft2_positions = draft2[:5]

    # เพิ่มข้อมูลเข้าไปใน data
    data.append([
        date, tournament, game, team1, 
        draft1_positions[0], draft1_positions[1], draft1_positions[2], draft1_positions[3], draft1_positions[4],
        ban1[0], ban1[1], 
        team2, 
        draft2_positions[0], draft2_positions[1], draft2_positions[2], draft2_positions[3], draft2_positions[4],
        ban2[0], ban2[1], 
        winner, length, vod
    ])

# สร้าง DataFrame และบันทึกเป็น Excel
df = pd.DataFrame(data, columns=columns)
df.to_excel("Game_History.xlsx", index=False)

print("บันทึกข้อมูลเป็น RoV_Pro_League_2025_Summer.xlsx เรียบร้อยแล้ว!")
